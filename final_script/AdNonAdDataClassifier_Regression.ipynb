{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Script Name : AdNonAdDataClassfier_Regression.ipynb\n",
    "#### Author : Sreejith Menon, Jairaj Shaktawat, Surbhi Arora, Pooja Donekal, Shvetha Suvarna\n",
    "#### Date : 11/07/2015\n",
    "#### Version: 1.0 Initial Draft\n",
    "####                 2.0 Added Logic for Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Getting the data ready for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dta = pd.read_csv('../data/ready_for_logistic_clean.csv')\n",
    "\n",
    "#printing a few statistics\n",
    "#print(dta.std())\n",
    "div_percentage = 0.75\n",
    "train_test_boundary = math.floor(div_percentage*len(dta))\n",
    "end_boundary = len(dta)\n",
    "train_data = dta[:train_test_boundary]\n",
    "test_data = dta[train_test_boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n"
     ]
    }
   ],
   "source": [
    "print(len(dta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_fl = csv.reader(open(\"../data/ready_for_logistic_clean.csv\",\"r\"))\n",
    "headers = full_fl.__next__()\n",
    "data = train_data[headers]\n",
    "test_data = test_data[headers]\n",
    "data['intercept'] = 1.0\n",
    "test_data['intercept'] = 1.0\n",
    "#print(data.head())\n",
    "\n",
    "headers_1 = headers\n",
    "headers_1.remove('class')\n",
    "headers_1.append('intercept')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "y = data['class']\n",
    "X = data[headers_1]\n",
    "logistic.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicition made on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = test_data['class']\n",
    "actual_class_val = []\n",
    "for i in range(train_test_boundary,end_boundary):\n",
    "    actual_class_val.append(y[i])\n",
    "\n",
    "# Predicted value\n",
    "predictions = logistic.predict(test_data[headers_1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n",
      "217\n",
      "86.8\n"
     ]
    }
   ],
   "source": [
    "## Calculating accuracy of training data set\n",
    "\n",
    "print(len(predictions))\n",
    "print(len(actual_class_val))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(0,(end_boundary-train_test_boundary)):\n",
    "    if predictions[i] == actual_class_val[i]:\n",
    "        count += 1\n",
    "        \n",
    "print(count)\n",
    "print(count*100/(end_boundary-train_test_boundary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
